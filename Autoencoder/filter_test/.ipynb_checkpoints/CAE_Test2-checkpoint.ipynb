{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.1085 - val_loss: 0.0804\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0785 - val_loss: 0.0760\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0742 - val_loss: 0.0713\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0722 - val_loss: 0.0700\n",
      "Epoch 5/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0709 - val_loss: 0.0699\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0701 - val_loss: 0.0694\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0694 - val_loss: 0.0692\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0689 - val_loss: 0.0679\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0685 - val_loss: 0.0679\n",
      "Epoch 10/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0681 - val_loss: 0.0679\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0679 - val_loss: 0.0669\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0676 - val_loss: 0.0669\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0674 - val_loss: 0.0669\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0671 - val_loss: 0.0665\n",
      "Epoch 15/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0670 - val_loss: 0.0666\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0668 - val_loss: 0.0667\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0666 - val_loss: 0.0666\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0665 - val_loss: 0.0658\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0664 - val_loss: 0.0661\n",
      "Epoch 20/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0662 - val_loss: 0.0658\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0661 - val_loss: 0.0658\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0659 - val_loss: 0.0654\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0658 - val_loss: 0.0656\n",
      "Epoch 25/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0658 - val_loss: 0.0655\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0656 - val_loss: 0.0655\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0655 - val_loss: 0.0653\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0655 - val_loss: 0.0654\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0654 - val_loss: 0.0650\n",
      "Epoch 30/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0653 - val_loss: 0.0649\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0653 - val_loss: 0.0652\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0652 - val_loss: 0.0649\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0651 - val_loss: 0.0651\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0651 - val_loss: 0.0646\n",
      "Epoch 35/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0650 - val_loss: 0.0647\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0650 - val_loss: 0.0646\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0649 - val_loss: 0.0645\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0649 - val_loss: 0.0643\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0648 - val_loss: 0.0643\n",
      "Epoch 40/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0648 - val_loss: 0.0643\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0647 - val_loss: 0.0646\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0647 - val_loss: 0.0645\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0646 - val_loss: 0.0643\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0646 - val_loss: 0.0642\n",
      "Epoch 45/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0645 - val_loss: 0.0643\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0645 - val_loss: 0.0642\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0645 - val_loss: 0.0640\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0644 - val_loss: 0.0641\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0644 - val_loss: 0.0641\n",
      "Epoch 50/50\n",
      "Save the image\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0643 - val_loss: 0.0640\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "initial_mode2 = keras.initializers.he_normal(seed=None)\n",
    "initial_mode = keras.initializers.glorot_normal(seed=None)\n",
    "\n",
    "for i in range(1,2):\n",
    "    ## Build the Convolution autoencoders model\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer=initial_mode)(input_img)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer=initial_mode)(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer=initial_mode)(x)\n",
    "    encoded = x\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer=initial_mode)(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer=initial_mode)(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',kernel_initializer=initial_mode2)(x)\n",
    "\n",
    "\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    from keras.datasets import mnist\n",
    "    import numpy as np\n",
    "\n",
    "    (x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "    x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "    from keras.callbacks import TensorBoard\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    class CustomSaver(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_begin(self, epoch, logs={}):            \n",
    "            loop = epoch + 1\n",
    "            \n",
    "            if loop%5 == 0:  # or save after some epoch, each k-th epoch etc.\n",
    "                print('Save the image')\n",
    "                decoded_imgs = autoencoder.predict(x_test)\n",
    "                img = decoded_imgs[0]\n",
    "                img = img.reshape(28,28)\n",
    "                \n",
    "                # save the img\n",
    "                current_dir = os.getcwd()\n",
    "                plt.imshow(img,'gray')\n",
    "                plt.savefig(current_dir+'/Decoded_img/Decoded_image_epoch'+str(loop)+'.png')\n",
    "\n",
    "\n",
    "    saver = CustomSaver()\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    result = autoencoder.fit(x_train, x_train,\n",
    "                                        epochs=50,\n",
    "                                        batch_size=128,\n",
    "                                        shuffle=True,\n",
    "                                        validation_data=(x_test, x_test),\n",
    "                                        callbacks=[saver,TensorBoard(log_dir=current_dir+'/tensorboard_data/New_lecun')])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#print(autoencoder.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#decoded_images = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('New_CAE_glorot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env_3.6",
   "language": "python",
   "name": "tensor_env_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
